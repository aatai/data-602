{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3n07xurnj8G"
   },
   "source": [
    "###  20 News Groups Corpus, Sample dataset included in scikit-learn\n",
    "A collection of almost 20,000 articles on 20 different topics or 'newsgroups'.   \n",
    "Corpus: Text Collection\n",
    "more info: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kZFnmJHrnlsw",
    "outputId": "3df2aeac-bd15-44cc-d198-da0d7f073404"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "twenty_groups = fetch_20newsgroups(subset='all', random_state=21) \n",
    "# we will do cross validation, so we fetch all data\n",
    "# random state again same for all of you, so you all have the same shuffling for having same results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uTwhcntfoVP-"
   },
   "source": [
    "### These are the groups that the text samples originated from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xRGFKl-1n8mz",
    "outputId": "4928d822-6d23-45bc-dbfe-ff2da3cb207f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_groups.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WiYrProcqDsI"
   },
   "source": [
    "#### Seeing what is the class of first entry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MulQjRg-ps3-",
    "outputId": "dbc04c61-20de-4058-8fce-4db883ff0e45"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=0\n",
    "twenty_groups.target[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxGou9XgqMzz"
   },
   "source": [
    "#### Index 9 is rec.sport.baseball, lets look at the first entry and see if it makes sense:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "id": "LJ0o51wep8UW",
    "outputId": "c29ac9c6-e80f-411e-dce1-a8c922a3edcb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From: hallam@dscomsa.desy.de (Phill Hallam-Baker)\\nSubject: Re: re: fillibuster\\nLines: 55\\nReply-To: hallam@zeus02.desy.de\\nOrganization: DESYDeutsches Elektronen Synchrotron, Experiment ZEUS bei HERA\\n\\n\\nIn article <1993Apr12.002302.5262@martha.utcc.utk.edu>, PA146008@utkvm1.utk.edu (David Veal) writes:\\n\\n|>>Come to that under the original plan there wasn\\'t meant to be anything\\n|>>much for the federal government to do except keep the British out.\\n|>\\n|>       That\\'s also untrue, but at least we\\'re wandering a little closer\\n|>toward reality.  That the Articles of Confederation fell apart is enough\\n|>proof it was there for just a tad bit more.\\n\\nWell yes and no. The Federalist papers are propaganda and it is therefore\\ndifficult to determine precisely what Maddison etc were up to from them. They\\ncertainly emphasised a limited role for the federal government but this\\nwas not necessarily their true position.\\n\\n|>>And like the house of lords which it is copied from it was given pretty\\n|>>wide powers. Unfortunately they started to use them and thus the gridlock\\n|>>set in.\\n|>\\n|>       I wasn\\'t aware the House of Lords had \"wide powers.\"  I was under the\\n|>impression is was pretty powerless compared to the House of Commons, and\\n|>certainly didn\\'t have almost equal their powers.  (The Senate is restricted\\n|>only that it may not introduce bills relating to raising revenue.)\\n\\nThe Senate was less powerful than the House of Lords in the period in question.\\nThe stripping of the powers of the House of Lords did not occur until 1914\\nand David Llloyd George\\'s budget. Even despite this the House of Lords has\\nconsiderable power even today and is far from a rubber stamping body. \\n\\n\\n|>       My reading of the Constitution and other writings gives me absolutely\\n|>no reason to believe the Senate wasn\\'t intended to make use of their \\n|>law-making powers.  In fact, grid-lock appears to have been designed\\n|>into the system, with the Senate being a more deliberative body to act\\n|>as a check on the more-often elected House.\\n\\nThe system is meant to be slow to react, the problem is that it ended up\\na bit too slow.\\n\\n\\n|>       On what basis do you suggest that the Senate was supposed to be\\n|>some sort of rubber-stamp for the House?  You\\'ll note that while the\\n|>President\\'s veto may be over-ridden, the House can\\'t do anything about\\n|>a \"veto\" by the Senate.\\n\\nThe Presiden\\'t veto was meant to be entirely separate. Until Bush abused it\\nin a quite extraordinary manner it was used more in accord with the intent\\nof being a check on unreasonable legislation. The veto was clearly regarded \\nas a completely last gasp measure its use was meant to be restricted to\\npreventing the legislature interfering with the actions of the executive.\\n\\nthe Senate is not meant to be exactly a rubber stamp body, it is meant as\\na check on unrestrained legislation. That is the extra measure built into\\nthe constitution in favour of the status quo, 60% of the representatives\\nof the states is not a reasonable restriction. \\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_groups.data[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86Lp9LaIo6yP"
   },
   "source": [
    "## Q1: Is the full dataset balanced for each class? Do a barchart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "NrEG-p9t0sUr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "23943\n",
      "495\n",
      "12405\n",
      "2058\n",
      "418\n",
      "4885\n",
      "5115\n",
      "436\n",
      "1741\n",
      "1058\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5QAAAJgCAYAAAD1QizzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3df7Dld13f8dfbLEELaILZZGJ+sKirNdIaZBtDseNWNITQNtgKJk4h42DXsaGj0s6wWqdh/DETfwAd/BGNJSU4SIgKw1KiMUSsVSBmAyE/iJg1RrImJYuJitLqBD7943x3PF3u3rv3fe/dc+/m8Zg5c8/5nO/33M/57Ll37/Oec763xhgBAACA1fqCRU8AAACArUlQAgAA0CIoAQAAaBGUAAAAtAhKAAAAWgQlAAAALSsGZVWdU1Xvr6r7qureqvq+afx1VfVnVXXndLpkbp8frKoDVfXxqnrR3PjF09iBqto7N/7sqrqtqu6vqndU1cnrfUcBAABYX7XS36GsqjOTnDnG+HBVPSPJHUlemuTlSf56jPHTR2x/XpK3J7kgyZcleV+Sr5qu/qMk35rkYJLbk1w+xvhYVd2Y5J1jjBuq6heSfHSMcc1y8zrttNPGjh07VnVnAQAAWL077rjjU2OM7UeOb1tpxzHGI0kemc5/uqruS3LWMrtcmuSGMcbfJvmTqjqQWVwmyYExxgNJUlU3JLl0ur1vTvKd0zbXJ3ldkmWDcseOHdm/f/9K0wcAAGCNqupPlxpf1Xsoq2pHkucmuW0aenVV3VVV11XVqdPYWUkemtvt4DR2tPEvTfIXY4wnjhgHAABgEzvmoKyqpyf59STfP8b4q8yeQfyKJOdn9gzm6w9vusTuozG+1Bz2VNX+qtp/6NChY506AAAAG+CYgrKqnpJZTL5tjPHOJBljfHKM8dkxxueS/FL+/mWtB5OcM7f72UkeXmb8U0lOqaptR4x/njHGtWOMXWOMXdu3f97LdwEAADiOjuUor5XkzUnuG2O8YW78zLnNvi3JPdP5fUkuq6qnVtWzk+xM8geZHYRn53RE15OTXJZk35gdFej9Sb592v+KJO9e290CAABgo614UJ4kL0jyiiR3V9Wd09gPJbm8qs7P7OWpDyb5niQZY9w7HbX1Y0meSHLlGOOzSVJVr05yc5KTklw3xrh3ur3XJrmhqn4syUcyC1gAAAA2sRX/bMhmtWvXruEorwAAABuvqu4YY+w6cnxVR3kFAACAwwQlAAAALYISAACAFkEJAABAi6AEAACgRVACAADQIigBAABoEZQAAAC0CEoAAABaBCUAAAAtghIAAIAWQQkAAECLoAQAAKBFUAIAANAiKAEAAGgRlAAAALQISgAAAFoEJQAAAC2CEgAAgJZti57AiWjH3vcuegoL9eDVL1n0FAAAgOPAM5QAAAC0CEoAAABaBCUAAAAtghIAAIAWQQkAAECLoAQAAKBFUAIAANAiKAEAAGgRlAAAALQISgAAAFoEJQAAAC2CEgAAgBZBCQAAQIugBAAAoEVQAgAA0CIoAQAAaBGUAAAAtAhKAAAAWgQlAAAALYISAACAFkEJAABAi6AEAACgRVACAADQIigBAABoEZQAAAC0CEoAAABaBCUAAAAtghIAAIAWQQkAAECLoAQAAKBFUAIAANAiKAEAAGgRlAAAALQISgAAAFoEJQAAAC2CEgAAgBZBCQAAQIugBAAAoEVQAgAA0CIoAQAAaBGUAAAAtAhKAAAAWgQlAAAALYISAACAFkEJAABAi6AEAACgRVACAADQIigBAABoEZQAAAC0CEoAAABaBCUAAAAtghIAAIAWQQkAAECLoAQAAKBFUAIAANAiKAEAAGgRlAAAALQISgAAAFoEJQAAAC2CEgAAgBZBCQAAQIugBAAAoEVQAgAA0CIoAQAAaBGUAAAAtAhKAAAAWgQlAAAALYISAACAFkEJAABAi6AEAACgRVACAADQIigBAABoEZQAAAC0CEoAAABaBCUAAAAtghIAAIAWQQkAAECLoAQAAKBFUAIAANAiKAEAAGgRlAAAALQISgAAAFoEJQAAAC2CEgAAgBZBCQAAQIugBAAAoGXFoKyqc6rq/VV1X1XdW1XfN40/s6puqar7p4+nTuNVVW+qqgNVdVdVff3cbV0xbX9/VV0xN/68qrp72udNVVUbcWcBAABYP8fyDOUTSf7jGONrklyY5MqqOi/J3iS3jjF2Jrl1upwkL06yczrtSXJNMgvQJFcl+YYkFyS56nCETtvsmdvv4rXfNQAAADbSikE5xnhkjPHh6fynk9yX5Kwklya5ftrs+iQvnc5fmuStY+ZDSU6pqjOTvCjJLWOMx8YYjye5JcnF03VfPMb44BhjJHnr3G0BAACwSa3qPZRVtSPJc5PcluSMMcYjySw6k5w+bXZWkofmdjs4jS03fnCJcQAAADaxYw7Kqnp6kl9P8v1jjL9abtMlxkZjfKk57Kmq/VW1/9ChQytNGQAAgA10TEFZVU/JLCbfNsZ45zT8yenlqpk+PjqNH0xyztzuZyd5eIXxs5cY/zxjjGvHGLvGGLu2b99+LFMHAABggxzLUV4ryZuT3DfGeMPcVfuSHD5S6xVJ3j03/srpaK8XJvnL6SWxNye5qKpOnQ7Gc1GSm6frPl1VF06f65VztwUAAMAmte0YtnlBklckubuq7pzGfijJ1UlurKpXJflEkpdN192U5JIkB5J8Jsl3JckY47Gq+tEkt0/b/cgY47Hp/PcmeUuSL0ryG9MJAACATWzFoBxj/F6Wfp9jkrxwie1HkiuPclvXJbluifH9SZ6z0lwAAADYPFZ1lFcAAAA4TFACAADQIigBAABoEZQAAAC0CEoAAABaBCUAAAAtghIAAIAWQQkAAECLoAQAAKBFUAIAANAiKAEAAGgRlAAAALQISgAAAFoEJQAAAC2CEgAAgBZBCQAAQIugBAAAoEVQAgAA0CIoAQAAaBGUAAAAtAhKAAAAWgQlAAAALYISAACAFkEJAABAi6AEAACgRVACAADQIigBAABoEZQAAAC0CEoAAABaBCUAAAAtghIAAIAWQQkAAECLoAQAAKBFUAIAANAiKAEAAGgRlAAAALQISgAAAFoEJQAAAC2CEgAAgBZBCQAAQIugBAAAoEVQAgAA0CIoAQAAaBGUAAAAtAhKAAAAWgQlAAAALYISAACAFkEJAABAi6AEAACgRVACAADQIigBAABoEZQAAAC0CEoAAABaBCUAAAAtghIAAIAWQQkAAECLoAQAAKBFUAIAANAiKAEAAGgRlAAAALQISgAAAFoEJQAAAC2CEgAAgBZBCQAAQIugBAAAoEVQAgAA0CIoAQAAaBGUAAAAtAhKAAAAWgQlAAAALYISAACAFkEJAABAi6AEAACgRVACAADQIigBAABoEZQAAAC0CEoAAABaBCUAAAAtghIAAIAWQQkAAECLoAQAAKBFUAIAANAiKAEAAGgRlAAAALQISgAAAFoEJQAAAC2CEgAAgBZBCQAAQIugBAAAoEVQAgAA0CIoAQAAaBGUAAAAtAhKAAAAWgQlAAAALYISAACAFkEJAABAi6AEAACgRVACAADQIigBAABoEZQAAAC0CEoAAABaBCUAAAAtghIAAIAWQQkAAECLoAQAAKBlxaCsquuq6tGqumdu7HVV9WdVded0umTuuh+sqgNV9fGqetHc+MXT2IGq2js3/uyquq2q7q+qd1TVyet5BwEAANgYx/IM5VuSXLzE+BvHGOdPp5uSpKrOS3JZkq+d9vn5qjqpqk5K8nNJXpzkvCSXT9smyU9Mt7UzyeNJXrWWOwQAAMDxsWJQjjF+N8ljx3h7lya5YYzxt2OMP0lyIMkF0+nAGOOBMcbfJbkhyaVVVUm+OcmvTftfn+Slq7wPAAAALMBa3kP56qq6a3pJ7KnT2FlJHprb5uA0drTxL03yF2OMJ44YBwAAYJPrBuU1Sb4iyflJHkny+mm8lth2NMaXVFV7qmp/Ve0/dOjQ6mYMAADAumoF5Rjjk2OMz44xPpfklzJ7SWsye4bxnLlNz07y8DLjn0pySlVtO2L8aJ/32jHGrjHGru3bt3emDgAAwDppBWVVnTl38duSHD4C7L4kl1XVU6vq2Ul2JvmDJLcn2Tkd0fXkzA7cs2+MMZK8P8m3T/tfkeTdnTkBAABwfG1baYOqenuS3UlOq6qDSa5Ksruqzs/s5akPJvmeJBlj3FtVNyb5WJInklw5xvjsdDuvTnJzkpOSXDfGuHf6FK9NckNV/ViSjyR587rdOwAAADbMikE5xrh8ieGjRt8Y48eT/PgS4zcluWmJ8Qfy9y+ZBQAAYItYy1FeAQAAeBITlAAAALQISgAAAFoEJQAAAC2CEgAAgBZBCQAAQIugBAAAoEVQAgAA0CIoAQAAaBGUAAAAtAhKAAAAWgQlAAAALYISAACAFkEJAABAi6AEAACgRVACAADQIigBAABoEZQAAAC0CEoAAABaBCUAAAAtghIAAIAWQQkAAECLoAQAAKBFUAIAANAiKAEAAGgRlAAAALQISgAAAFoEJQAAAC2CEgAAgBZBCQAAQIugBAAAoEVQAgAA0CIoAQAAaBGUAAAAtAhKAAAAWgQlAAAALYISAACAFkEJAABAi6AEAACgRVACAADQIigBAABoEZQAAAC0CEoAAABaBCUAAAAtghIAAIAWQQkAAECLoAQAAKBFUAIAANAiKAEAAGgRlAAAALQISgAAAFoEJQAAAC2CEgAAgBZBCQAAQIugBAAAoGXboicArK8de9+76Cks1INXv2TRUwAAeNLwDCUAAAAtghIAAIAWQQkAAECLoAQAAKBFUAIAANAiKAEAAGgRlAAAALQISgAAAFoEJQAAAC2CEgAAgBZBCQAAQIugBAAAoEVQAgAA0CIoAQAAaBGUAAAAtAhKAAAAWgQlAAAALYISAACAFkEJAABAi6AEAACgRVACAADQIigBAABoEZQAAAC0CEoAAABaBCUAAAAtghIAAIAWQQkAAECLoAQAAKBFUAIAANAiKAEAAGgRlAAAALQISgAAAFoEJQAAAC2CEgAAgBZBCQAAQIugBAAAoEVQAgAA0CIoAQAAaBGUAAAAtAhKAAAAWgQlAAAALYISAACAFkEJAABAi6AEAACgRVACAADQIigBAABoEZQAAAC0CEoAAABaBCUAAAAtghIAAICWFYOyqq6rqker6p65sWdW1S1Vdf/08dRpvKrqTVV1oKruqqqvn9vnimn7+6vqirnx51XV3dM+b6qqWu87CQAAwPo7lmco35Lk4iPG9ia5dYyxM8mt0+UkeXGSndNpT5JrklmAJrkqyTckuSDJVYcjdNpmz9x+R34uAAAANqEVg3KM8btJHjti+NIk10/nr0/y0rnxt46ZDyU5parOTPKiJLeMMR4bYzye5JYkF0/XffEY44NjjJHkrXO3BQAAwCbWfQ/lGWOMR5Jk+nj6NH5Wkofmtjs4jS03fnCJcQAAADa59T4oz1LvfxyN8aVvvGpPVe2vqv2HDh1qThEAAID10A3KT04vV8308dFp/GCSc+a2OzvJwyuMn73E+JLGGNeOMXaNMXZt3769OXUAAADWQzco9yU5fKTWK5K8e278ldPRXi9M8pfTS2JvTnJRVZ06HYznoiQ3T9d9uqounI7u+sq52wIAAGAT27bSBlX19iS7k5xWVQczO1rr1UlurKpXJflEkpdNm9+U5JIkB5J8Jsl3JckY47Gq+tEkt0/b/cgY4/CBfr43syPJflGS35hOAAAAbHIrBuUY4/KjXPXCJbYdSa48yu1cl+S6Jcb3J3nOSvMAAABgc1nvg/IAAADwJCEoAQAAaBGUAAAAtAhKAAAAWgQlAAAALYISAACAFkEJAABAi6AEAACgRVACAADQIigBAABoEZQAAAC0CEoAAABaBCUAAAAtghIAAIAWQQkAAECLoAQAAKBFUAIAANAiKAEAAGgRlAAAALQISgAAAFoEJQAAAC2CEgAAgBZBCQAAQIugBAAAoEVQAgAA0CIoAQAAaBGUAAAAtAhKAAAAWgQlAAAALYISAACAFkEJAABAi6AEAACgRVACAADQIigBAABoEZQAAAC0CEoAAABaBCUAAAAtghIAAIAWQQkAAECLoAQAAKBFUAIAANAiKAEAAGgRlAAAALQISgAAAFoEJQAAAC2CEgAAgBZBCQAAQIugBAAAoEVQAgAA0CIoAQAAaBGUAAAAtAhKAAAAWgQlAAAALYISAACAFkEJAABAi6AEAACgRVACAADQIigBAABoEZQAAAC0CEoAAABaBCUAAAAtghIAAIAWQQkAAECLoAQAAKBFUAIAANAiKAEAAGgRlAAAALQISgAAAFoEJQAAAC2CEgAAgBZBCQAAQIugBAAAoEVQAgAA0CIoAQAAaBGUAAAAtAhKAAAAWgQlAAAALYISAACAFkEJAABAi6AEAACgRVACAADQIigBAABoEZQAAAC0CEoAAABaBCUAAAAtghIAAIAWQQkAAECLoAQAAKBFUAIAANAiKAEAAGgRlAAAALQISgAAAFoEJQAAAC2CEgAAgBZBCQAAQIugBAAAoEVQAgAA0CIoAQAAaBGUAAAAtAhKAAAAWgQlAAAALYISAACAFkEJAABAi6AEAACgRVACAADQsqagrKoHq+ruqrqzqvZPY8+sqluq6v7p46nTeFXVm6rqQFXdVVVfP3c7V0zb319VV6ztLgEAAHA8rMczlP98jHH+GGPXdHlvklvHGDuT3DpdTpIXJ9k5nfYkuSaZBWiSq5J8Q5ILklx1OEIBAADYvLZtwG1emmT3dP76JL+T5LXT+FvHGCPJh6rqlKo6c9r2ljHGY0lSVbckuTjJ2zdgbgDACWzH3vcuegoL9eDVL1n0FIAnmbU+QzmS/FZV3VFVe6axM8YYjyTJ9PH0afysJA/N7XtwGjvaOAAAAJvYWp+hfMEY4+GqOj3JLVX1h8tsW0uMjWXGP/8GZtG6J0nOPffc1c4VAACAdbSmZyjHGA9PHx9N8q7M3gP5yemlrJk+PjptfjDJOXO7n53k4WXGl/p8144xdo0xdm3fvn0tUwcAAGCN2kFZVU+rqmccPp/koiT3JNmX5PCRWq9I8u7p/L4kr5yO9nphkr+cXhJ7c5KLqurU6WA8F01jAAAAbGJrecnrGUneVVWHb+dXxhi/WVW3J7mxql6V5BNJXjZtf1OSS5IcSPKZJN+VJGOMx6rqR5PcPm33I4cP0AMATzYOKuOgMgBbSTsoxxgPJPm6Jcb/PMkLlxgfSa48ym1dl+S67lwAAAA4/tbj71ACAADwJCQoAQAAaBGUAAAAtAhKAAAAWgQlAAAALYISAACAFkEJAABAi6AEAACgRVACAADQIigBAABoEZQAAAC0CEoAAABaBCUAAAAtghIAAIAWQQkAAECLoAQAAKBFUAIAANAiKAEAAGgRlAAAALQISgAAAFoEJQAAAC2CEgAAgBZBCQAAQIugBAAAoEVQAgAA0CIoAQAAaBGUAAAAtAhKAAAAWgQlAAAALYISAACAFkEJAABAi6AEAACgRVACAADQIigBAABoEZQAAAC0CEoAAABaBCUAAAAtghIAAIAWQQkAAECLoAQAAKBFUAIAANAiKAEAAGgRlAAAALQISgAAAFoEJQAAAC2CEgAAgBZBCQAAQIugBAAAoEVQAgAA0CIoAQAAaBGUAAAAtAhKAAAAWgQlAAAALYISAACAFkEJAABAi6AEAACgRVACAADQIigBAABoEZQAAAC0CEoAAABaBCUAAAAtghIAAIAWQQkAAEDLtkVPAGAz2bH3vYuewsI9ePVLFj0FAGCL8AwlAAAALYISAACAFkEJAABAi6AEAACgRVACAADQIigBAABo8WdDAABgHTzZ//SUPzv15OQZSgAAAFoEJQAAAC2CEgAAgBZBCQAAQIugBAAAoEVQAgAA0CIoAQAAaBGUAAAAtAhKAAAAWgQlAAAALYISAACAFkEJAABAi6AEAACgRVACAADQIigBAABo2bboCQAAAOzY+95FT2GhHrz6JYueQotnKAEAAGgRlAAAALQISgAAAFoEJQAAAC2CEgAAgBZBCQAAQIugBAAAoEVQAgAA0CIoAQAAaBGUAAAAtAhKAAAAWrYtegJwpB1737voKSzUg1e/ZNFTAACAY+IZSgAAAFo8QwnAuvIqA68yYOvy9evrF1bLM5QAAAC0CEoAAABaBCUAAAAtghIAAIAWQQkAAEDLpgnKqrq4qj5eVQeqau+i5wMAAMDyNkVQVtVJSX4uyYuTnJfk8qo6b7GzAgAAYDmbIiiTXJDkwBjjgTHG3yW5IcmlC54TAAAAy9gsQXlWkofmLh+cxgAAANikaoyx6Dmkql6W5EVjjO+eLr8iyQVjjP9wxHZ7kuyZLn51ko8f14luHacl+dSiJ7GFWb+1sX5rY/3WzhqujfVbG+u3NtZvbazf2li/5T1rjLH9yMFti5jJEg4mOWfu8tlJHj5yozHGtUmuPV6T2qqqav8YY9ei57FVWb+1sX5rY/3WzhqujfVbG+u3NtZvbazf2li/ns3yktfbk+ysqmdX1clJLkuyb8FzAgAAYBmb4hnKMcYTVfXqJDcnOSnJdWOMexc8LQAAAJaxKYIyScYYNyW5adHzOEF4WfDaWL+1sX5rY/3WzhqujfVbG+u3NtZvbazf2li/hk1xUB4AAAC2ns3yHkoAAAC2GEG5iVTV7qr6p4uex2FV9eNV9VBV/fUR4+dW1fur6iNVdVdVXbKoOc7bQuv3mqr62LR2t1bVsxY1x+VswvX8jmnN7q2qn1z0fFaymdavqp5RVXfOnT5VVf910fNazmZavySpqt+sqo9Oj79fqKqTFj2nI23CNTva98CnVtU7qupAVd1WVTsWM8Oj22xreVhV7auqexY9j6VstjVb5vH3xrnvhX9UVX+xqDkezVZZy81sE67hyVV17fSY+8Oq+jeLntN6EpSby+4kG/rgr5lj/Xd/T5ILlhj/4SQ3jjGem9kReX9+vea3RruzNdbvI0l2jTH+cZJfS7JZ42h3Nsl6VtWXJvmpJC8cY3xtkjOq6oUbObd1sDubZP3GGJ8eY5x/+JTkT5O8cyPntg52Z5Os3+TlY4yvS/KcJNuTvGzjZta2O5trzY72PfBVSR4fY3xlkjcm+Yn1mt862p3NtZapqn+dZDP/QL87m2vNlnz8jTF+YO574c9kc34v3J0tsJab3O5srjX8z0keHWN8VZLzkvzPjZvZAowxnDbwlOSVSe5K8tEkvzyN/cskt2UWFu9LckaSHUn+d5I/S3Jnkn+W2Q8tv57Zn1W5PckLpv23J7klyYeT/GJmPxyeNl33miT3TKfvn8Z2JLkvs/D7SJKrkrxxbo7/LskblrkPf33E5V9M8trp/POTfMD6Hfv6HXHdc5P8vsfj8uuZ5J8ked/c5Vck+Xlfz63H484kD2V6D731W/X6PSWzH66+w5od85od+X/IzUmeP53fltkfEd/wx+NWXsskT0/ye5n9IHqPr9l1+z/4A0m+1VqufS2t4Ypfww8ledoi129D/20WPYET+ZTka5N8fO6B+czp46n5+wMifXeS10/nX5fkP83t/ytJvnE6f26S+6bzP5vkB6fzFycZSU5L8rwkdyd5Wmb/+dybWbDsSPK5JBdO+zwtyR8necp0+QNJ/tEy9+PIHwbOnD7PwSSPJ3me9Tv29Tviup9N8sMej8uv5zTHg9O+2zL7T+E9x2PdToT1O+J+/JckP3081+5EWb/MQujxaS4nWbP2/yH3JDl77vIfH76P1nLptczsmdxvm/Y/LkG51dfsaI+/ufFnJXkkvpbX5ecZa7jszzCnZBaUb8gsXH81yRmLWsuNOG2aPxtygvrmJL82xvhUkowxHpvGz07yjqo6M8nJSf7kKPt/S5Lzqurw5S+uqmck+cbM/mPJGOM3q+rx6fpvTPKuMcbfJElVvTOz38rsS/KnY4wPTfv8TVX9dpJ/UVX3ZfZFcPcq7tflSd4yxnh9VT0/yS9X1XPGGJ9bxW0cixN1/TLd/r9NsivJN61236Ytu55jjMer6nuTvCOzb+QfSPLl/aVo2bLrd4TLMnuG93jb8us3xnhRVX1hkrdN9+eWxjqsxpZfs6OoJcbGKvbv2LJrWVXnJ/nKMcYP1PF9v+mWXbNjdNl0/z7b2He1TvS1PB628hpum+b5+2OM11TVa5L8dBbzf/GGEJQbq7L0f5I/k9nT4fuqandmv0VZyhdk9rKg//P/3ejcV8MSn+9o/uaIy/8tyQ8l+cMk/32Z/Zbyqsx+i5MxxgenH7BOS/LoKm9nJSfq+qWqviWz19N/0xjjb1e7f9OWXs8xxnsye6lhqmpPkuPxQ8C8Lb1+0+f6uiTbxhh3LHPbG2XLr1+SjDH+b1XtS3JpNj4oT4g1W8LBJOckOVhV25J8SZLHlt9lzbbyWj4/yfOq6sHMfm47vap+Z4yxe5nPsR628podi8uSXNncd7VO9LU8HrbyGv55ks8kedd0+Vcz+1n6hOGgPBvr1iQvr9kBRVJVz5zGvySz13UnyRVz2386yTPmLv9WklcfvjD9ljKZvY/i5dPYRZk93Z8kv5vkpVX1D6rqaZn9xuV/LTWxMcZtmf2H/p1J3r7K+/WJJC+cPv/XJPnCJIdWeRvH4oRcv6p6bmav0/9XY4z1jvDlbOn1rKrTp4+nJvn3mX0DP5629PpNLl/h+o20Zdevqp4+/fY7UwBdktkPDhtty67ZCvbNzfvbk/z2GGOjn6Hcsms5xrhmjPFlY4wdmT1r8kfHISaTLbxmK6mqr54+7wdXu2/TCbuWx9GWXcPp+9t7MjtQUDL7Gfpjy97brWap18E6rd8pswf3PZm9gfgt09ilSR7I7IH5U0l+Zxr/qszebHz4DcSnZfYSv7sye+D9wrTd6Zl9YX04s/dVPJzkqdN1R3sD8ee95yLJ3iQ3LDP3n8zsN8mfmz6+bho/L8nvT/fpziQXWb9Vrd/7knxymuedSfZ5PB7Ter59+rwfS3KZr+fVrd+0zQNJ/uEi1m4rr19mB3m4ffrc92b2G/Ft1qz9PfALM/sN/YEkfxWb8DQAAADcSURBVJDky63lyl+/y+1vzY798Tdd97okVx+vdTyR19IaHvMaPiuzSL1r+nznLmINN+p0+E2sbCFV9dQknx1jPFGz9zBeM2aHv17t7fyPzI5Mdeu6T3ITs37ry3qujfVbG+u3etZs/VjL1bNm68darp01XB/eQ7k1nZvkxpr97Zu/y+wQxcesqk7J7LfCH32SPvCt3/qynmtj/dbG+q2eNVs/1nL1rNn6sZZrZw3XgWcoAQAAaHFQHgAAAFoEJQAAAC2CEgAAgBZBCQAAQIugBAAAoEVQAgAA0PL/AENwEiaUiE5yAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ANSWER to Q1 goes here\n",
    "########################\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,2,2])\n",
    "langs = twenty_groups.target_names\n",
    "print(langs)\n",
    "numbers = []\n",
    "categories = []\n",
    "dataset = {}\n",
    "for i in range(0,20):\n",
    "    numbers.append(len(twenty_groups.data[i]))\n",
    "    categories.append(twenty_groups.target[i])\n",
    "    categoryName = 'category ' + str(twenty_groups.target[i])\n",
    "    if (categoryName not in dataset):\n",
    "        dataset[categoryName] = len(twenty_groups.data[i])\n",
    "    else:\n",
    "        dataset[categoryName] += len(twenty_groups.data[i])\n",
    "\n",
    "for i in dataset:\n",
    "    print(dataset[i])\n",
    "ax.bar(dataset.keys(),dataset.values())\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QwqiL_VhxuKU"
   },
   "source": [
    "We want to work on a binary classification example.\n",
    "Let's focus on one class 'misc.forsale', and name the rest as others.\n",
    "\n",
    "Or let's say we wanted to have a model for detecting sales related emails, and \n",
    "used this dataset to train that model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UeeVDVyUo5Su",
    "outputId": "3645018f-60ca-4372-c6f7-6e7507bf31a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(twenty_groups.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "NoRsgDTDyKTB"
   },
   "outputs": [],
   "source": [
    "twenty_groups.target_names.append('others')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wr7shlJCyRsq",
    "outputId": "1d5d0bf0-5265-4c68-ddd7-b862e1b708fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twenty_groups.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OrPwRVSSzIu4",
    "outputId": "833a6667-ced1-4cee-ad7b-1c59822e8aba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 alt.atheism\n",
      "1 comp.graphics\n",
      "2 comp.os.ms-windows.misc\n",
      "3 comp.sys.ibm.pc.hardware\n",
      "4 comp.sys.mac.hardware\n",
      "5 comp.windows.x\n",
      "6 misc.forsale\n",
      "7 rec.autos\n",
      "8 rec.motorcycles\n",
      "9 rec.sport.baseball\n",
      "10 rec.sport.hockey\n",
      "11 sci.crypt\n",
      "12 sci.electronics\n",
      "13 sci.med\n",
      "14 sci.space\n",
      "15 soc.religion.christian\n",
      "16 talk.politics.guns\n",
      "17 talk.politics.mideast\n",
      "18 talk.politics.misc\n",
      "19 talk.religion.misc\n",
      "20 others\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,21):\n",
    "  print(str(i) + \" \" + twenty_groups.target_names[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mFxHrhrwytxL"
   },
   "source": [
    "Since first class was 0, 'others' class will be index 20, we need to replace \n",
    "everything except 6 (\"misc.forsale\") with 20 in the target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6lN4yBwSyUty",
    "outputId": "1bf9c3b2-24aa-4247-989a-f336bee8eeaf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_groups.target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "QfwAWEUyzl8R"
   },
   "outputs": [],
   "source": [
    "twenty_groups.target[0]=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XfBCfz05zsBG",
    "outputId": "87cc3f4e-8a06-4cd2-c1c0-288e04912c45"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_groups.target[0] # I checked if I could really modify it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jzrTYRRz0HhF",
    "outputId": "19bc5368-0b8c-44a5-c035-293ecff374f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_groups.target[1] #second element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Z2un6GK0VcE",
    "outputId": "b5a63199-3aea-41bb-ad35-106c88761172"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_groups.target[-1] #last element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "6F7frxRcztrR"
   },
   "outputs": [],
   "source": [
    "class_to_keep = 6\n",
    "# now do it in a loop\n",
    "for i in range(0,len(twenty_groups.target)):\n",
    "  if twenty_groups.target[i]!= class_to_keep:\n",
    "    twenty_groups.target[i]=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3uA38BMu0bgj",
    "outputId": "829dbb02-1697-4ee8-aab6-a3ce726a9942"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_groups.target[1] #second element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aRR01f_k0eF3",
    "outputId": "0e06d319-a3c9-470d-fa93-249b0da4b0e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_groups.target[-1] #last element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mmHisB810i4R"
   },
   "source": [
    "## Q2:Do another barchart to see the new class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "dGewGi-P0foM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc', 'others']\n",
      "51496\n",
      "1058\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ANSWER to Q2 goes here\n",
    "########################\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,2,2])\n",
    "langs = twenty_groups.target_names\n",
    "print(langs)\n",
    "numbers = []\n",
    "categories = []\n",
    "dataset = {}\n",
    "for i in range(0,20):\n",
    "    numbers.append(len(twenty_groups.data[i]))\n",
    "    categories.append(twenty_groups.target[i])\n",
    "    categoryName = 'category ' + str(twenty_groups.target[i])\n",
    "    if (categoryName not in dataset):\n",
    "        dataset[categoryName] = len(twenty_groups.data[i])\n",
    "    else:\n",
    "        dataset[categoryName] += len(twenty_groups.data[i])\n",
    "\n",
    "for i in dataset:\n",
    "    print(dataset[i])\n",
    "ax.bar(dataset.keys(),dataset.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "YYWVSaTHpc7n"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Split the data to have a 10% validation set. \n",
    "twenty_g_X_train, twenty_g_X_test, twenty_g_y_train, twenty_g_y_test = \\\n",
    "train_test_split(twenty_groups.data, twenty_groups.target, \n",
    "                 test_size=0.10, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CNVro6IT1ncl"
   },
   "source": [
    "**PRE Q3:** Let's create a pipeline that creates the vectors representing the documents, and then classify them using 5 Nearest Neighbor classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NRZ50e1H1kjS",
    "outputId": "1f7a20c2-054d-497b-c1a0-481f002b6a97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:   22.2s remaining:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   34.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_word...\n",
       "                                                        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                                        tokenizer=None,\n",
       "                                                        use_idf=True,\n",
       "                                                        vocabulary=None)),\n",
       "                                       ('model',\n",
       "                                        KNeighborsClassifier(algorithm='auto',\n",
       "                                                             leaf_size=30,\n",
       "                                                             metric='minkowski',\n",
       "                                                             metric_params=None,\n",
       "                                                             n_jobs=None,\n",
       "                                                             n_neighbors=5, p=2,\n",
       "                                                             weights='uniform'))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1, param_grid={}, pre_dispatch='2*n_jobs',\n",
       "             refit=True, return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "pipe = Pipeline([('vect', TfidfVectorizer(stop_words='english')),\n",
    "                 ('model', KNeighborsClassifier())])\n",
    "\n",
    "# and do a gridsearchCV to do cross validation \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# We are not doing hyperparameter optimization, so empty parameters dictionary passed\n",
    "# Using GridSearchCV here, only for cross validation \n",
    "parameters = {}\n",
    "grid_search = GridSearchCV(pipe, parameters, cv=10, verbose=1,n_jobs=-1)\n",
    "\n",
    "# Running the experiments \n",
    "grid_search.fit(twenty_g_X_train, twenty_g_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3f_yDSlG17vH"
   },
   "source": [
    "**PreQ3c**: This is one way to display classification report: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N77qUBjDaeBO",
    "outputId": "de5ab8d3-6804-422d-a78a-360225481c8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    for-sale       0.81      0.39      0.53       107\n",
      "      others       0.96      0.99      0.98      1778\n",
      "\n",
      "    accuracy                           0.96      1885\n",
      "   macro avg       0.89      0.69      0.75      1885\n",
      "weighted avg       0.96      0.96      0.95      1885\n",
      "\n",
      "Accuracy: 0.9602122015915119\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Using the predictor found to be best to predict the validation set\n",
    "predicted1 = grid_search.predict(twenty_g_X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(twenty_g_y_test,\n",
    "                            predicted1, \n",
    "                            target_names=[\"for-sale\", \"others\"]))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy:\", accuracy_score(twenty_g_y_test, predicted1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66df1il3tF6p"
   },
   "source": [
    "## Q3a: GridSearchCV for hyperparameter optimization\n",
    "Rerun this experiment to see which k in kNN, gives best f1-score \n",
    "Use \n",
    "```\n",
    "parameters = {\"model__n_neighbors\" : range(1,11,3)}\n",
    "```\n",
    "you will be testing for k values  [1, 4, 7, 10]\n",
    "\n",
    "The experiments may take 5-10 minutes, as kNN classifier is not really a model, \n",
    "but compares with all entries in runtime!\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "M4esnvj4Pu-O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([12.72182894, 13.02992451, 13.07652125, 12.66231887]),\n",
       " 'std_fit_time': array([0.37765238, 0.34419899, 0.57058798, 0.31706102]),\n",
       " 'mean_score_time': array([5.26055501, 5.74979377, 5.66579933, 5.13332677]),\n",
       " 'std_score_time': array([0.24038484, 0.32958553, 0.39569806, 0.23372256]),\n",
       " 'param_model__n_neighbors': masked_array(data=[1, 4, 7, 10],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'model__n_neighbors': 1},\n",
       "  {'model__n_neighbors': 4},\n",
       "  {'model__n_neighbors': 7},\n",
       "  {'model__n_neighbors': 10}],\n",
       " 'split0_test_score': array([0.96464349, 0.96582204, 0.96876841, 0.96758986]),\n",
       " 'split1_test_score': array([0.96641131, 0.96464349, 0.96523276, 0.95992929]),\n",
       " 'split2_test_score': array([0.96758986, 0.96523276, 0.95816146, 0.95757219]),\n",
       " 'split3_test_score': array([0.96639151, 0.96403302, 0.9634434 , 0.96285377]),\n",
       " 'split4_test_score': array([0.97169811, 0.9634434 , 0.96639151, 0.9634434 ]),\n",
       " 'split5_test_score': array([0.96875   , 0.96639151, 0.96580189, 0.96698113]),\n",
       " 'split6_test_score': array([0.96757075, 0.96285377, 0.96403302, 0.96462264]),\n",
       " 'split7_test_score': array([0.96698113, 0.96108491, 0.96108491, 0.96049528]),\n",
       " 'split8_test_score': array([0.96873156, 0.9640118 , 0.95988201, 0.96106195]),\n",
       " 'split9_test_score': array([0.96224189, 0.96460177, 0.96460177, 0.96519174]),\n",
       " 'mean_test_score': array([0.967101  , 0.96421202, 0.96374035, 0.96297388]),\n",
       " 'std_test_score': array([0.0024    , 0.00144948, 0.00304607, 0.00305792]),\n",
       " 'rank_test_score': array([1, 2, 3, 4])}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANSWER to Q3a goes here\n",
    "########################\n",
    "parameters = {\"model__n_neighbors\" :  [1, 4, 7, 10]}\n",
    "grid_search = GridSearchCV(pipe, parameters, cv=10, verbose=1,n_jobs=-1)\n",
    "grid_search.fit(twenty_g_X_train, twenty_g_y_train)\n",
    "grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-_xF933E8P4N",
    "outputId": "336c5fd5-820c-42c9-d0f5-1cc7e322e3e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words='english',\n",
       "                                                        stri...\n",
       "                                                        vocabulary=None)),\n",
       "                                       ('model',\n",
       "                                        LinearSVC(C=1.0, class_weight=None,\n",
       "                                                  dual=True, fit_intercept=True,\n",
       "                                                  intercept_scaling=1,\n",
       "                                                  loss='squared_hinge',\n",
       "                                                  max_iter=1000,\n",
       "                                                  multi_class='ovr',\n",
       "                                                  penalty='l2',\n",
       "                                                  random_state=None, tol=0.0001,\n",
       "                                                  verbose=0))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None, param_grid={},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "pipe = Pipeline([('vect', TfidfVectorizer(stop_words='english')),\n",
    "                 ('model', LinearSVC())])\n",
    "\n",
    "# and do a gridsearchCV to do cross validation \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# We are not doing hyperparameter optimization, so empty parameters dictionary passed\n",
    "# Using GridSearchCV here, only for cross validation \n",
    "parameters = {}\n",
    "grid_search = GridSearchCV(pipe, parameters, cv=10, verbose=1)\n",
    "\n",
    "# Running the experiments \n",
    "grid_search.fit(twenty_groups.data, twenty_groups.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xlVYTaL50-ox"
   },
   "source": [
    "## Q3b: Run again for 2,3\n",
    "in 3a, you must found best accuracy happened at 1 and 4, so you want to look at 2, 3 too, maybe best is between k=1 and k=4.\n",
    "use \n",
    "\n",
    "\n",
    "```\n",
    "parameters = {\"model__n_neighbors\" : (2, 3)}\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BwfF2er1094C"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3581vAct7BzZ"
   },
   "source": [
    "\n",
    "For the best performing kNN classifier you found, \n",
    "##Q3c:  display classification_report like above in PreQc3, and \n",
    "##Q3d: the confusion matrix..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "3oChYF7dP1L9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   56.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([12.20923157, 11.44001815]),\n",
       " 'std_fit_time': array([0.2994141 , 0.59101905]),\n",
       " 'mean_score_time': array([5.24476895, 5.13335609]),\n",
       " 'std_score_time': array([0.33644668, 0.52398775]),\n",
       " 'param_model__n_neighbors': masked_array(data=[2, 3],\n",
       "              mask=[False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'model__n_neighbors': 2}, {'model__n_neighbors': 3}],\n",
       " 'split0_test_score': array([0.95992929, 0.96817914]),\n",
       " 'split1_test_score': array([0.95757219, 0.96582204]),\n",
       " 'split2_test_score': array([0.96110784, 0.96700059]),\n",
       " 'split3_test_score': array([0.95341981, 0.96462264]),\n",
       " 'split4_test_score': array([0.95931604, 0.96757075]),\n",
       " 'split5_test_score': array([0.96049528, 0.96757075]),\n",
       " 'split6_test_score': array([0.95813679, 0.96757075]),\n",
       " 'split7_test_score': array([0.95283019, 0.95990566]),\n",
       " 'split8_test_score': array([0.96165192, 0.96696165]),\n",
       " 'split9_test_score': array([0.9539823 , 0.96578171]),\n",
       " 'mean_test_score': array([0.95784447, 0.9660987 ]),\n",
       " 'std_test_score': array([0.00313795, 0.00230426]),\n",
       " 'rank_test_score': array([2, 1])}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANSWER to Q3c goes here\n",
    "########################\n",
    "parameters = {\"model__n_neighbors\" : (2, 3)}\n",
    "grid_search = GridSearchCV(pipe, parameters, cv=10, verbose=1,n_jobs=-1)\n",
    "grid_search.fit(twenty_g_X_train, twenty_g_y_train)\n",
    "grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    for-sale       0.85      0.50      0.63       107\n",
      "      others       0.97      0.99      0.98      1778\n",
      "\n",
      "    accuracy                           0.97      1885\n",
      "   macro avg       0.91      0.75      0.80      1885\n",
      "weighted avg       0.96      0.97      0.96      1885\n",
      "\n",
      "Accuracy: 0.96657824933687\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Using the predictor found to be best to predict the validation set\n",
    "predicted1 = grid_search.predict(twenty_g_X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(twenty_g_y_test,\n",
    "                            predicted1, \n",
    "                            target_names=[\"for-sale\", \"others\"]))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy:\", accuracy_score(twenty_g_y_test, predicted1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "QGyVuPZXP6Ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  53,   54],\n",
       "       [   9, 1769]], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ANSWER to Q3d goes here\n",
    "########################\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(twenty_g_y_test, predicted1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW2-DocumentClassification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
